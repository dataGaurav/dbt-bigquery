# dbt CI/CD Pipeline
#
# Production branch: main. Merging a PR into main triggers a push to main → CD job runs automatically.
#
# High-Level Workflow:
#   PR targeting main → CI runs (compile, seed, run, test in staging). After review, merge to main.
#   Merge to main    → Push event to main → CD job runs automatically (dbt run + dbt test in PROD).
#   workflow_dispatch → Run CD manually from Actions tab if needed.
#
# Gate (PR): A deliberate dbt test failure in a PR fails CI → with branch protection, merge is blocked → no deploy.
# Gate: The gate that prevents deploy when tests fail is at merge time (CI). Require "CI (compile & test)" before merge.
# CD: dbt run first (create/update models), then dbt test. Tests need objects to exist; if we ran test first, test would fail when prod is empty or on first deploy.
# Required: Settings → Branches (main) → Require status check "CI (compile & test)" to pass before merge.
#
# Required secrets:
#   GCP_SA_KEY_DEV  - Service account JSON for the DEV BigQuery project (CI uses this for staging/temp; same project, different dataset)
#   GCP_SA_KEY_PROD - Service account JSON for the PROD BigQuery project (CD)
#
# Required variables: DBT_BQ_PROJECT_DEV, DBT_BQ_PROJECT_PROD. Optional: DBT_BQ_DATASET_STAGING (default: dbt_gpoojary_staging). Python models are excluded from deploy.

name: dbt CI/CD

on:
  pull_request:
    branches: [main]   # PR targeting main → CI runs
  push:
    branches: [main]   # Merge to main → push event → CD runs automatically
  workflow_dispatch:   # Run CD manually from Actions tab if needed

env:
  # Use repo's profiles.yml (dev, staging, prod); workflow sets DBT_TARGET and env vars
  DBT_PROFILES_DIR: ${{ github.workspace }}
  PYTHON_VERSION: "3.11"

jobs:
  # --- CI Phase: dbt compile + dbt test against staging/temp environment ---
  ci:
    name: CI (compile & test)
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dbt-bigquery
        run: pip install dbt-bigquery

      - name: Install package dependencies
        run: dbt deps

      - name: Write dev credentials (staging uses dev project, staging dataset only)
        run: echo '${{ secrets.GCP_SA_KEY_DEV }}' > "${{ github.workspace }}/sa-dev.json"
        env:
          GCP_SA_KEY_DEV: ${{ secrets.GCP_SA_KEY_DEV }}

      - name: dbt compile
        run: dbt compile
        env:
          DBT_TARGET: staging
          DBT_KEYFILE_DEV: ${{ github.workspace }}/sa-dev.json
          DBT_BQ_PROJECT_DEV: ${{ vars.DBT_BQ_PROJECT_DEV }}
          DBT_BQ_DATASET_STAGING: ${{ vars.DBT_BQ_DATASET_STAGING }}

      - name: dbt seed
        run: dbt seed
        env:
          DBT_TARGET: staging
          DBT_KEYFILE_DEV: ${{ github.workspace }}/sa-dev.json
          DBT_BQ_PROJECT_DEV: ${{ vars.DBT_BQ_PROJECT_DEV }}
          DBT_BQ_DATASET_STAGING: ${{ vars.DBT_BQ_DATASET_STAGING }}

      - name: dbt run
        run: dbt run --exclude is_holiday_2025
        env:
          DBT_TARGET: staging
          DBT_KEYFILE_DEV: ${{ github.workspace }}/sa-dev.json
          DBT_BQ_PROJECT_DEV: ${{ vars.DBT_BQ_PROJECT_DEV }}
          DBT_BQ_DATASET_STAGING: ${{ vars.DBT_BQ_DATASET_STAGING }}

      - name: dbt test
        run: dbt test
        env:
          DBT_TARGET: staging
          DBT_KEYFILE_DEV: ${{ github.workspace }}/sa-dev.json
          DBT_BQ_PROJECT_DEV: ${{ vars.DBT_BQ_PROJECT_DEV }}
          DBT_BQ_DATASET_STAGING: ${{ vars.DBT_BQ_DATASET_STAGING }}

      - name: Remove credentials
        if: always()
        run: rm -f "${{ github.workspace }}/sa-dev.json" "${{ github.workspace }}/sa-prod.json" 2>/dev/null || true

  # --- CD Phase: dbt run first (models must exist for tests), then dbt test. Gate = CI must pass before merge. ---
  cd:
    name: CD (run & test in prod)
    runs-on: ubuntu-latest
    if: (github.event_name == 'push' && github.ref == 'refs/heads/main') || github.event_name == 'workflow_dispatch'
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dbt-bigquery
        run: pip install dbt-bigquery

      - name: Install package dependencies
        run: dbt deps

      - name: Write prod credentials
        run: echo '${{ secrets.GCP_SA_KEY_PROD }}' > "${{ github.workspace }}/sa-prod.json"
        env:
          GCP_SA_KEY_PROD: ${{ secrets.GCP_SA_KEY_PROD }}

      - name: dbt seed
        run: dbt seed
        env:
          DBT_TARGET: prod
          DBT_KEYFILE_PROD: ${{ github.workspace }}/sa-prod.json
          DBT_BQ_PROJECT_PROD: ${{ vars.DBT_BQ_PROJECT_PROD }}
          DBT_BQ_DATASET_PROD: ${{ vars.DBT_BQ_DATASET_PROD || 'dbt_prod' }}

      # Run so models/tables exist; otherwise dbt test would fail (no objects in prod on first deploy or empty state)
      # Optional: add --vars '{"run_legacy_audit": true}' to run the legacy audit model in prod
      - name: dbt run
        run: dbt run --exclude is_holiday_2025
        env:
          DBT_TARGET: prod
          DBT_KEYFILE_PROD: ${{ github.workspace }}/sa-prod.json
          DBT_BQ_PROJECT_PROD: ${{ vars.DBT_BQ_PROJECT_PROD }}
          DBT_BQ_DATASET_PROD: ${{ vars.DBT_BQ_DATASET_PROD || 'dbt_prod' }}

      - name: dbt test
        run: dbt test
        env:
          DBT_TARGET: prod
          DBT_KEYFILE_PROD: ${{ github.workspace }}/sa-prod.json
          DBT_BQ_PROJECT_PROD: ${{ vars.DBT_BQ_PROJECT_PROD }}
          DBT_BQ_DATASET_PROD: ${{ vars.DBT_BQ_DATASET_PROD || 'dbt_prod' }}

      - name: Remove credentials
        if: always()
        run: rm -f "${{ github.workspace }}/sa-dev.json" "${{ github.workspace }}/sa-prod.json" 2>/dev/null || true
